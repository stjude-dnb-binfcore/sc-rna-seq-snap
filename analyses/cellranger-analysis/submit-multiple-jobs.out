/research_jude/rgs01_jude/dept/DNB/core_operations/Bioinformatics/achroni/GitHub/pipeline-testing/sc-rna-seq-snap
Job <242034060> is submitted to queue <standard>.
Job <242034067> is submitted to queue <standard>.

------------------------------------------------------------
Sender: LSF System <lsfadmin@noderome229>
Subject: Job 242034058: <submit-multiple-jobs> in cluster <hpcf_research_cluster> Done

Job <submit-multiple-jobs> was submitted from host <noderome230> by user <achroni> in cluster <hpcf_research_cluster> at Thu Nov 14 13:54:07 2024
Job was executed on host(s) <noderome229>, in queue <standard>, as user <achroni> in cluster <hpcf_research_cluster> at Thu Nov 14 13:54:25 2024
</home/achroni> was used as the home directory.
</research/dept/dnb/core_operations/Bioinformatics/achroni/GitHub/pipeline-testing/sc-rna-seq-snap/analyses/cellranger-analysis/.> was used as the working directory.
Started at Thu Nov 14 13:54:25 2024
Terminated at Thu Nov 14 13:55:27 2024
Results reported at Thu Nov 14 13:55:27 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

#BSUB -P run_cellranger
#BSUB -J submit-multiple-jobs
#BSUB -q standard
#BSUB -n 1
#BSUB -R "rusage[mem=2500]"
#BSUB -o submit-multiple-jobs.out
#BSUB -e submit-multiple-jobs.err
#BSUB -cwd "."

########################################################################
# Read root path
rootdir=$(realpath "./../..")
echo "$rootdir" 

########################################################################
# Set up variables
prefix="${rootdir}/analyses/cellranger-analysis"

########################################################################
# Create directories to save output files to
mkdir -p ${prefix}/input
mkdir -p ${prefix}/results

########################################################################
# File in which we store the output text to verify the job execution order.
# As the jobs will run on the cluster, we pass in a path to the directory from
# which this launch script was run so everyone writes to the same file.
output_file="output.txt"

# Prints a simple LSF job file to standard output
function print_job {
    outfile=${1}
    delay_seconds=${2}

    # Preamble
    echo "#!/bin/bash"

    # Variables
    echo "time=\`date\`"
    echo "name=\${LSB_JOBNAME}"

    # Describe job when it comes online, delay, then write completion text
    echo "echo \"Online: name=\${name} time=\${time}\" >> ${outfile}"
    echo "sleep ${delay_seconds}"
    echo "echo \"Done: name=\${name}\" >> ${outfile}"
}

# Generate the LSF job files

(... more ...)
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   0.22 sec.
    Max Memory :                                 7 MB
    Average Memory :                             6.54 MB
    Total Requested Memory :                     2500.00 MB
    Delta Memory :                               2493.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                5
    Run time :                                   62 sec.
    Turnaround time :                            80 sec.

The output (if any) is above this job summary.



PS:

Read file <submit-multiple-jobs.err> for stderr output of this job.

