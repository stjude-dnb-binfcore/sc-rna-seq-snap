---
title: "Final filtering for downstream analyses for sc-/sn-RNA-Seq Analysis in 10X Genomics data"
author: "Antonia Chroni for SJCRH DNB_BINF_Core"
papersize: a4
fontsize: 11pt
links-as-notes: true
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    df_print: paged
    code_folding: hide
    toc_depth: 2
    highlight: tango
    number_sections: TRUE
  pdf_document:
    toc: TRUE
    highlight: tango
    number_sections: TRUE
    latex_engine: lualatex
    keep_tex: FALSE
    fig_caption: yes
    fig_crop: no
    fig_height: 2
    fig_width: 3
    toc_depth: 2
always_allow_html: TRUE
urlcolor: blue
linkcolor: black
citecolor: blue
geometry: margin=1in
header-includes: 
  - \usepackage{titling}
  - \usepackage{fancyhdr}
  - \usepackage{graphicx}
  - \usepackage{float}
params:
  grouping: "."
  genome_name: "."
  Regress_Cell_Cycle_value: "."
  assay: "."
  normalize_method: "."
  num_pcs: "."
  num_dim: "."
  num_neighbors: "."
  nfeatures_value: "."
  prefix: "."
  use_SoupX_filtering: "."
  use_scDblFinder_filtering: "."
  use_condition_split: "."
  condition_value1: "."
  condition_value2: "."
  condition_value3: "."
  print_pdf: "."
  PCA_Feature_List_value: "."
  root_dir: './'
  metadata_dir: './'
  metadata_file: '.'
  PROJECT_NAME: '.'
  PI_NAME: '.'
  TASK_ID: '.'
  PROJECT_LEAD_NAME: '.'
  DEPARTMENT: '.'
  LEAD_ANALYSTS: '.'
  GROUP_LEAD: '.'
  CONTACT_EMAIL: '.'
  PIPELINE: '.'
  START_DATE: '.'
  COMPLETION_DATE: '.'
---

```{r logo-file, echo=FALSE}
attach(params)
# Insert logo on the top of the html report 
logo_file <- file.path(root_dir, "figures", "img", "DNB-BINF-Core-logo.png")
htmltools::img(src = knitr::image_uri(logo_file), alt = "logo", style = "position:absolute; top:0; left:0; padding:0px; height:120px;")
detach(params)
```


\addtolength{\headheight}{2.0cm} 
\fancypagestyle{plain}{} 
\thispagestyle{fancy}
\fancyhead[L]{\includegraphics[height=120px]{`r logo_file`}}
\renewcommand{\headrulewidth}{0pt}

<style type="text/css">
:root {--DNB_BINF_Core_color: #00427B;}

h1.title {margin-top: 130px;
          margin-bottom: 25px;
          font-size: 36px;}

.nobullet li {list-style-type: none;}

.reporthead {font-size: 20px;}

body { /* Normal */
  font-size: 16px;
  font-style: Arial, Helvetica, sans-serif;}

h1 {color: var(--DNB_BINF_Core_color);
    font-size: 28px;
    margin-top: 50px;}

h2 {color: var(--DNB_BINF_Core_color);
    font-size: 20px;}

.list-group-item.active, .list-group-item.active:focus, .list-group-item.active:hover {
  background-color: var(--DNB_BINF_Core_color);}
</style>

<a href="https://wiki.stjude.org/display/CAB">

</a>

\pagebreak

<div class="reporthead"><br/>
**PI: `r params$PI_NAME`**  
**Project: `r params$PROJECT_NAME`**  
Task: `r params$TASK_ID`  
Project Lead(s): `r params$PROJECT_LEAD_NAME`  
Department: `r params$DEPARTMENT`  

<br />  

DNB Bioinformatics Core Analysis Team: 
<br />  

>**Lead Analyst(s): `r params$LEAD_ANALYSTS`**  
>Group Lead: `r params$GROUP_LEAD`  
<br />
>**Contact E-mail:** `r params$CONTACT_EMAIL`  
>**DNB Bioinformatics Core Pipeline:** `r params$PIPELINE`  

Date started: `r params$START_DATE`  
Date completed:  `r params$COMPLETION_DATE`  
Report generated: `r format(Sys.time(), '%H:%M:%S %Z %m/%d/%Y')` \

Reviewed by: _____________________   Date: ____________ \
</div>
\pagebreak
  
# Information about this notebook
This notebook combines the following matrices to filter out any low-quality cells and contamination.
1. `seurat_obj.rds` as generated by the Seurat workflow and miQC R package,
2. `SoupX_corrected_mtx_merged.rds` as generated by the SoupX method, and
3. `merged_seurat_obj_with_doublets.rds` as generated by the scDblFinder method.

# Set up
```{r load-library, echo=TRUE}
suppressPackageStartupMessages({
  library(devtools)
  library(future)
  library(Seurat)
  library(patchwork)
  library(tidyverse)
  library(ggthemes)
  library(scooter)
  library(RColorBrewer)
  library(knitr)
  
  # Evaluate Seurat R expressions asynchronously when possible using future package
  options(future.globals.maxSize = future_globals_value) 
  plan(multisession, workers = parallelly::availableCores())})
```

```{r echo=FALSE,warning=FALSE}
opts_chunk$set(fig.align='center',
               external=TRUE,
               echo=FALSE,
               warning=FALSE,
               fig.pos='H')
a4width <- 8.3
a4height <- 11.7
```

# Directories and paths to file Inputs/Outputs
```{r set-dir-and-file-names, echo=TRUE}
attach(params)
analysis_dir <- file.path(root_dir, "analyses", "upstream-analysis") 
module_results_dir <- file.path(analysis_dir, "results")
seurat_results_dir <- file.path(analysis_dir, "results", "02_Seurat_qc") 
#SoupX_results_dir <- file.path(analysis_dir, "results", "01_SoupX") 
scDblFinder_results_dir <- file.path(analysis_dir, "results", "03_scDblFinder") 
module_plots_dir <- file.path(analysis_dir, "plots") 

# Input files
seurat_results_file <- c(dir(path = seurat_results_dir,  pattern = "seurat_obj.rds", full.names = TRUE, recursive = TRUE))
#SoupX_file <- file.path(SoupX_results_dir, "SoupX_corrected_mtx_merged.rds")
scDblFinder_file <- file.path(scDblFinder_results_dir, "merged_seurat_obj_with_doublets.rds")
project_metadata_file <- file.path(metadata_dir, metadata_file) # metadata input file
gradient_palette_file <- file.path(root_dir, "figures", "palettes", "gradient_color_palette.tsv")

# Create results_dir
results_dir <- file.path(module_results_dir, "04_Filter_object")
if (!dir.exists(results_dir)) {
  dir.create(results_dir)}

# Create plots directory
plots_dir <- file.path(module_plots_dir, "04_Filter_object") 
if (!dir.exists(plots_dir)) {
  dir.create(plots_dir)}

source(paste0(root_dir, "/figures/scripts/theme_plot.R"))
source(paste0(analysis_dir, "/util/function-process-Seurat.R"))
source(paste0(analysis_dir, "/util/function-create-UMAP.R"))
```

# Read metadata file and define `sample_name`
```{r read-metadata-define-sample-name, echo=TRUE}
# Read metadata
project.metadata <- read.csv(project_metadata_file, sep = '\t', header = TRUE)
sample_name <- unique(as.character(project.metadata$ID))
sample_name <- sort(sample_name, decreasing = FALSE)
print(sample_name)
```

```{r define-parameters-for-plots, echo=TRUE}
# Read color palette
gradient_palette_df <- readr::read_tsv(gradient_palette_file, guess_max = 100000, show_col_types = FALSE) 
```

# Read and merge `seurat_qc` object
First, we will merge the `seurat_obj.rds` objects from all samples in the project as generated by the `seurat_qc` pipeline.

```{r read-merge-objects, echo=TRUE}
# Create list 
seurat_obj_list <- list()

for (i in seq_along(sample_name)) {
  # Check if the file exists
  if (file.exists(seurat_results_file[i])) {
    cat("Reading in data for sample:", sample_name[i], "\n")
    seurat_obj_list[i] <- readRDS(seurat_results_file[i])
  } else {
    cat("File does not exist for sample:", sample_name[i], "\n")
  }
}

# Print the list of Seurat objects
print(seurat_obj_list)

# Merge all seurat objects in the list into one 
# The first parameter of merge should be a Seurat object, the second (y) can be one Seurat object or a list of several.
seurat_obj <- merge(x = seurat_obj_list[[1]], y = seurat_obj_list[-1],
                    project = PROJECT_NAME)
print(DefaultAssay(seurat_obj) <- "RNA") # Switch the default to RNA
saveRDS(seurat_obj, file = paste0(results_dir, "/", "seurat_obj_merged.rds")) # Save merged object
#############################################################################
# Estimate `cells_number_seurat_qc` per sample_name
cells_number_seurat_qc <- table(seurat_obj@meta.data$orig.ident) %>%
    as.data.frame() %>% 
    mutate(sample_name = Var1,
           cells_number_seurat_qc = Freq) %>% 
    dplyr::select(-Var1, -Freq)
```

# Filter ambient RNA
Next, we will use the corrected matrices from all samples as generated by [SoupX](https://cran.r-project.org/web/packages/SoupX/vignettes/pbmcTutorial.html). This is an optional step, so it will be skipped or not as defined in `params`. 

```{r filter-ambient-RNA, echo=TRUE}
# Indicates whether or not to use the SoupX corrected matrix for filtering or to skip it
if (use_SoupX_filtering == "YES"){
  print_message <- "we will use SoupX corrected matrix"
  #SoupX_seurat_obj <- readRDS(SoupX_file) # Read SoupX_seurat_obj
  #colnames(seurat_obj)[which(!(colnames(seurat_obj) %in% colnames(SoupX_seurat_obj) ))]
  #seurat_obj <- subset(seurat_obj, cells=colnames(seurat_obj)[which(!(colnames(seurat_obj) %in% colnames(SoupX_seurat_obj) ))], invert=TRUE)
  #SoupX_seurat_obj <- SoupX_seurat_obj[,colnames(seurat_obj)]
  #seurat_obj[["RNA_SoupX"]] <- CreateAssayObject(counts = seurat_obj[["RNA"]])
  seurat_obj <- RenameAssays(seurat_obj, RNA = "RNA_SoupX")
  DefaultAssay(seurat_obj) <- "RNA_SoupX"

  cat("Cells_number_after_filter_ambient_RNA per orig.ident", "\n")
  print(table(seurat_obj@meta.data$orig.ident))
  cat("Cells_number_after_filter_ambient_RNA per ID", "\n")
  print(table(seurat_obj@meta.data$ID))
  } else {
    print_message <- "we will skip usage of the SoupX corrected matrix"}
```

Here, `r print_message`.

# Filter doublets out
Next, we will remove any doublets from all samples as identified by [ScDblFinder](https://bioconductor.org/packages/devel/bioc/vignettes/scDblFinder/inst/doc/scDblFinder.html). This is an optional step, so it will be skipped or not as defined in params.

```{r filter-doublets, echo=TRUE}
# Read scDblFinder results
scDblFinder_obj <- readRDS(scDblFinder_file)

#############################################################################
# Estimate `cells_number_raw` per sample_name
cells_number_raw <- table(scDblFinder_obj@meta.data$orig.ident) %>%
  as.data.frame() %>% 
  mutate(sample_name = Var1,
        cells_number_raw = Freq) %>% 
  dplyr::select(-Var1, -Freq)

if (use_scDblFinder_filtering == "YES"){
  print_message_doublets <- "we will use scDblFinder to remove doublets"
  #############################################################################
  # Add metadata
  # Check if there are duplicated column names
  if (any(duplicated(names(scDblFinder_obj@meta.data)))) {
    # Identify duplicated columns
    duplicated_columns <- which(duplicated(names(scDblFinder_obj@meta.data)))
  
    # Remove columns with duplicated names
    scDblFinder_obj@meta.data <- scDblFinder_obj@meta.data[, -duplicated_columns]
    cat("Duplicated columns removed.\n")
    } else {
      scDblFinder_obj@meta.data <- scDblFinder_obj@meta.data
      cat("No duplicated columns found.\n")
      }
  
  # Add metadata   
  metadata <- as_data_frame_seurat(scDblFinder_obj, metadata = TRUE) 
  seurat_obj@meta.data <- merge_metadata(seurat_obj, metadata) 
  
  # Check if there are duplicated column names
  if (any(duplicated(names(seurat_obj@meta.data)))) {
    # Identify duplicated columns
    duplicated_columns <- which(duplicated(names(seurat_obj@meta.data)))
  
    # Remove columns with duplicated names
    seurat_obj@meta.data <- seurat_obj@meta.data[, -duplicated_columns]
    cat("Duplicated columns removed.\n")
    } else {
      seurat_obj@meta.data <- seurat_obj@meta.data
      cat("No duplicated columns found.\n")
    }
  
  ##########################################################################################################
  # Report Singlets 
  singlet_cells <- colnames(scDblFinder_obj)[which(scDblFinder_obj@meta.data$scDblFinder.class == "singlet")]
  
  ##########################################################################################################
  # Report Doublets
  seurat_obj_doublets <- subset(seurat_obj, cells = singlet_cells, invert = TRUE)

  cells_number_doublets <- table(seurat_obj_doublets@meta.data$orig.ident) %>%
    as.data.frame() %>% 
    mutate(sample_name = Var1,
           cells_number_doublets = Freq) %>% 
    dplyr::select(-Var1, -Freq)

  doublet_cells <- colnames(seurat_obj)[which(seurat_obj@meta.data$scDblFinder.class == "doublet")]

  ##########################################################################################################
  # Filter Doublets out
  cells_filter <- unique(doublet_cells) # identify unique cells to filter
  seurat_obj <- subset(seurat_obj, cells = cells_filter, invert = TRUE)

  ##########################################################################################################
  # Estimate `cells_number_final` per sample_name
  cells_number_final <- table(seurat_obj@meta.data$orig.ident) %>%
    as.data.frame() %>% 
    mutate(sample_name = Var1,
           cells_number_final = Freq) %>% 
    dplyr::select(-Var1, -Freq)
  } else {
    print_message_doublets <- "we will skip usage of the scDblFinder to remove doublets"
    ##########################################################################################################
    cells_number_doublets <- table(seurat_obj@meta.data$orig.ident) %>%
      as.data.frame() %>%
      #mutate_at(('Freq'), ~replace_na(.,0)) %>%
      mutate(sample_name = Var1,
             cells_number_doublets ='NA') %>% #0
      dplyr::select(-Var1, -Freq) 
   
    ##########################################################################################################
    # Estimate `cells_number_final` per sample_name
    cells_number_final <- table(seurat_obj@meta.data$orig.ident) %>%
      as.data.frame() %>% 
      mutate(sample_name = Var1) %>% 
      dplyr::select(-Var1, -Freq) %>%
      left_join(cells_number_seurat_qc) %>%
      dplyr::rename(cells_number_final = cells_number_seurat_qc) 
}
```

Here, `r print_message_doublets`.

# Number of cells per sample at each QC step
We will summarize the number of cells per sample at each QC step.

```{r}
# Create `cells_table` per sample_name
suppressWarnings(suppressMessages(cells_table  <- cells_number_raw %>%
                                    left_join(cells_number_seurat_qc) %>%
                                    left_join(cells_number_doublets) %>%
                                    left_join(cells_number_final)))

# Save table 
write_tsv(cells_table, paste0(results_dir, "/", "number_of_cells_per_sample.tsv")) 
```

```{r, fig.align = "left", results = "asis", message = FALSE, warning = FALSE, echo = FALSE}
tables1 <- cells_table
cat("  \n<div align=\"center\" style=\"font-size:80%\">  \n")
caption_value = "Summary of number of cells per sample at each QC step"
print(knitr::kable(tables1, align = "lcccc", caption = caption_value))
cat("  \n</div>  \n")
cat("  \n\\pagebreak  \n")
```

# Process seurat object
The next steps include: 

## Normalization of the data
After removing unwanted cells from the dataset, the next step is to normalize the data. By default, we employ a global-scaling normalization method “LogNormalize” that normalizes the feature expression measurements for each cell by the total expression, multiplies this by a scale factor (10,000 by default), and log-transforms the result. 

## Identification of highly variable features (feature selection)
Next, we will calculate a subset of features that exhibit high cell-to-cell variation in the dataset (i.e, they are highly expressed in some cells, and lowly expressed in others). We and others have found that focusing on these genes in downstream analysis helps to highlight biological signal in single-cell datasets. By default, Seurat returns 2,000 features per dataset. These will be used in downstream analysis, like PCA.

## Scaling the data
Next, we apply a linear transformation (‘scaling’) that is a standard pre-processing step prior to dimensional reduction techniques like PCA. 

## Perform linear dimensional reduction (PCA) and Run non-linear dimensional reduction (UMAP)
Next we perform PCA on the scaled data. By default, only the previously determined variable features are used as input, but can be defined using features argument if you wish to choose a different subset (if you do want to use a custom subset of features, make sure you pass these to ScaleData first). For the first principal components, Seurat outputs a list of genes with the most positive and negative loadings, representing modules of genes that exhibit either correlation (or anti-correlation) across single-cells in the dataset. Next, we will run UMAP to visualize and explore the data. The goal of non-linear dimensional reduction algorithms is to learn underlying structure in the dataset, in order to place similar cells together in low-dimensional space. Therefore, cells that are grouped together within graph-based clusters determined above should co-localize on these dimension reduction plots.

```{r process-seurat, fig.width = 10, fig.height = 5, fig.fullwidth = TRUE, echo = TRUE}
cat("Create and process seurat", "\n")
seurat_obj <- Process_Seurat(seurat_obj = seurat_obj, nfeatures_value = nfeatures_value, Genome = genome_name,
                             Regress_Cell_Cycle = Regress_Cell_Cycle_value, assay = assay, num_pcs = num_pcs, 
                             prefix = prefix, num_dim = num_dim, num_neighbors = num_neighbors, results_dir = results_dir, 
                             plots_output = plots_dir, use_condition_split = use_condition_split, 
                             condition1 = condition_value1, condition2 = condition_value2, condition3 = condition_value3, 
                             print_pdf = print_pdf, PCA_Feature_List = PCA_Feature_List_value)
```

# Save output files

```{r save_seurat}
saveRDS(seurat_obj, file = paste0(results_dir, "/", "seurat_obj_merged_filtered.rds"))
```

```{r echo=FALSE}
detach(params)
```

\pagebreak

# Session Info

```{r echo=TRUE}
sessionInfo()
```
